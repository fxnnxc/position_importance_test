{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-24 07:49:41,838] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import time\n",
    "import argparse\n",
    "import torch    \n",
    "\n",
    "from pit.dataset.mathematical_shapes import MathematicalShapesDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import GPT2LMHeadModel, GPT2Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_shapes=102\n",
    "train_dataset = MathematicalShapesDataset( # sum to not 100\n",
    "                                      train=True,\n",
    "                                      rule_indices=[0,4], \n",
    "                                      num_shapes=num_shapes,\n",
    "                                      num_samples=1000000, \n",
    "                                      return_rule_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda:0'\n",
    "config=GPT2Config(n_layer=2, vocab_size=train_dataset.vocab_len, eos_token_id=train_dataset.eos_token)\n",
    "model = GPT2LMHeadModel(config=config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['transformer.wte.weight', 'transformer.wpe.weight', 'transformer.h.0.ln_1.weight', 'transformer.h.0.ln_1.bias', 'transformer.h.0.attn.c_attn.weight', 'transformer.h.0.attn.c_attn.bias', 'transformer.h.0.attn.c_proj.weight', 'transformer.h.0.attn.c_proj.bias', 'transformer.h.0.ln_2.weight', 'transformer.h.0.ln_2.bias', 'transformer.h.0.mlp.c_fc.weight', 'transformer.h.0.mlp.c_fc.bias', 'transformer.h.0.mlp.c_proj.weight', 'transformer.h.0.mlp.c_proj.bias', 'transformer.h.1.ln_1.weight', 'transformer.h.1.ln_1.bias', 'transformer.h.1.attn.c_attn.weight', 'transformer.h.1.attn.c_attn.bias', 'transformer.h.1.attn.c_proj.weight', 'transformer.h.1.attn.c_proj.bias', 'transformer.h.1.ln_2.weight', 'transformer.h.1.ln_2.bias', 'transformer.h.1.mlp.c_fc.weight', 'transformer.h.1.mlp.c_fc.bias', 'transformer.h.1.mlp.c_proj.weight', 'transformer.h.1.mlp.c_proj.bias', 'transformer.ln_f.weight', 'transformer.ln_f.bias', 'lm_head.weight'])\n"
     ]
    }
   ],
   "source": [
    "dic = model.state_dict()\n",
    "print(dic.keys())\n",
    "# dv = model.device\n",
    "# dv\n",
    "\n",
    "# cv = torch.tensor([0, 1], device = dv)\n",
    "# cv.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7_24\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# datetime.today()            # 현재 날짜 가져오기\n",
    "\n",
    "# datetime.today().year        # 현재 연도 가져오기\n",
    "\n",
    "# datetime.today().month      # 현재 월 가져오기\n",
    "\n",
    "# datetime.today().day\n",
    "\n",
    "print(f'{datetime.today().month}_{datetime.today().day}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_shapes=102\n",
    "train_dataset = MathematicalShapesDataset( # sum to not 100\n",
    "                                    train=True,\n",
    "                                    rule_indices=[0,4], \n",
    "                                    num_shapes=num_shapes,\n",
    "                                    num_samples=1000000, \n",
    "                                    return_rule_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(train_dataset, batch_size=1)\n",
    "for i in loader:\n",
    "    i['input_ids'] = i['input_ids'].to(device)\n",
    "    i['labels'] = i['input_ids'].to(device)\n",
    "    output = model(**i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([109,  45, 104,  48, 102,  93, 109, 109])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    if not(i % 5) or (i==9):\n",
    "        print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dh",
   "language": "python",
   "name": "dh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
